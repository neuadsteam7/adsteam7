{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random\n",
    "\n",
    "dataset = pd.DataFrame.from_csv(\"https://raw.githubusercontent.com/LuisM78/Appliances-energy-prediction-data/master/energydata_complete.csv\")\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "n_samples = X_full.shape[0]\n",
    "n_features = X_full.shape[1]\n",
    "\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_full, y_full).mean()\n",
    "print(\"Score with the entire dataset = %.2f\" % score)\n",
    "\n",
    "# Add missing values in 75% of the lines\n",
    "missing_rate = 0.75\n",
    "n_missing_samples = int(np.floor(n_samples * missing_rate))\n",
    "missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,\n",
    "                                      dtype=np.bool),\n",
    "                             np.ones(n_missing_samples,\n",
    "                                     dtype=np.bool)))\n",
    "rng.shuffle(missing_samples)\n",
    "missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "\n",
    "# Estimate the score without the lines containing missing values\n",
    "X_filtered = X_full[~missing_samples, :]\n",
    "y_filtered = y_full[~missing_samples]\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_filtered, y_filtered).mean()\n",
    "print(\"Score without the samples containing missing values = %.2f\" % score)\n",
    "\n",
    "# Estimate the score after imputation of the missing values\n",
    "X_missing = X_full.copy()\n",
    "X_missing[np.where(missing_samples)[0], missing_features] = 0\n",
    "y_missing = y_full.copy()\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"forest\", RandomForestRegressor(random_state=0,\n",
    "                                                       n_estimators=100))])\n",
    "score = cross_val_score(estimator, X_missing, y_missing).mean()\n",
    "print(\"Score after imputation of the missing values = %.2f\" % score)\n",
    "\n",
    "\n",
    "class Cleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Takes in dataframe, performs cleaning if needed and returns cleaned dataframe\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def seconds(self, x):\n",
    "        sec = x.hour*3600+x.minute*60+x.second\n",
    "        return sec\n",
    "    \n",
    "    def day_week(self, z):\n",
    "        a=[]\n",
    "        for y in z:\n",
    "            if y == 0:\n",
    "                a.append('Monday')\n",
    "            elif y == 1:\n",
    "                a.append('Tuesday')\n",
    "            elif y == 2:\n",
    "                a.append('Wednesday')\n",
    "            elif y == 3:\n",
    "                a.append('Thrusday')\n",
    "            elif y == 4:\n",
    "                a.append('Friday')\n",
    "            elif y == 5:\n",
    "                a.append('Saturday')\n",
    "            elif y == 6:\n",
    "                a.append('Sunday')\n",
    "        return a\n",
    "    \n",
    "    def week(self, x):\n",
    "        a=[]\n",
    "        for y in x:\n",
    "            if y == 'Saturday' or y == 'Sunday':\n",
    "                a.append('weekend')\n",
    "            else:\n",
    "                a.append('weekday')\n",
    "        return a\n",
    "    \n",
    "    def one_hot_encode(self, Data):\n",
    "        label_encoder = LabelEncoder()\n",
    "        int_encoded = label_encoder.fit_transform(Data['week_status'])\n",
    "        int_encoded_day = label_encoder.fit_transform(Data['Day_Status'])\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
    "        int_encoded_day = int_encoded_day.reshape(len(int_encoded_day), 1)\n",
    "        newWeek = onehot_encoder.fit_transform(int_encoded)\n",
    "        newDay = onehot_encoder.fit_transform(int_encoded_day)\n",
    "        # new2 = label_encoder.inverse_transform([argmax(new[len(new)-1, :])])\n",
    "        Data.drop(['week_status', 'Day_Status'], axis=1, inplace=True)\n",
    "        Data['Friday'] = pd.Series(newDay[:,0], index=Data.index)\n",
    "        Data['Monday'] = pd.Series(newDay[:,1], index=Data.index)\n",
    "        Data['Saturday'] = pd.Series(newDay[:,2], index=Data.index)\n",
    "        Data['Sunday'] = pd.Series(newDay[:,3], index=Data.index)\n",
    "        Data['Thursday'] = pd.Series(newDay[:,4], index=Data.index)\n",
    "        Data['Tuesday'] = pd.Series(newDay[:,5], index=Data.index)\n",
    "        Data['Wednesday'] = pd.Series(newDay[:,6], index=Data.index)\n",
    "        Data['WeekDay'] = pd.Series(newWeek[:,0], index=Data.index)\n",
    "        Data['Weekend'] = pd.Series(newWeek[:,1], index=Data.index)\n",
    "        return Data\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        \"\"\"Adding the columns Day_Status, week_status and Num_sec_midnight\"\"\"\n",
    "        \n",
    "        df['Num_sec_midnight']=self.seconds(df.index)\n",
    "        z = df.index.dayofweek\n",
    "        df['Day_Status'] = z\n",
    "        df['Day_Status'] = self.day_week(df.Day_Status)\n",
    "        df['week_status'] = self.week(df.Day_Status)\n",
    "        \n",
    "        \"\"\"Performing one hot encoding on week_status and day_status columns\"\"\"\n",
    "        return df.apply(self.one_hot_encode(df))\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self\n",
    "\n",
    "\n",
    "class Normalizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        \"\"\"Performs Normalization on all the columns except for Appliances\"\"\"\n",
    "        for j in range(1, len(df.columns)-1,1):\n",
    "            df.iloc[:,[j]] = (df.iloc[:,[j]] - df.iloc[:,[j]].mean())/df.iloc[:,[j]].std()\n",
    "        return df\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"Returns `self` unless something different happens in train and test\"\"\"\n",
    "        return self\n",
    "    \n",
    "class SplitData(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, df, y=None):\n",
    "        y=centered_scaled_data['Appliances']\n",
    "        df4 = centered_scaled_data.iloc[:,1:]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df4, y, test_size=0.25)\n",
    "        train = X_train.join(y_train)\n",
    "        test = X_test.join(y_test)\n",
    "        train.to_csv(\"train.csv\")\n",
    "        test.to_csv(\"test.csv\")\n",
    "        return df\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "pipeline = Pipeline([(\"cleaner\", Cleaner()),\n",
    "                     (\"normalizer\", Normalizer()),\n",
    "                     (\"train_test_split\", SplitData())])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
